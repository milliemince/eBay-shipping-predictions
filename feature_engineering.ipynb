{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Selection and Engineering \n",
    "In this file, we attempt to understand feature importance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we can analyze the coefficients learned by our naive linear regression network to see which features were weighted most highly"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import datetime as dt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import scale\n",
    "from collections import Counter\n",
    "#import ziptotimezone as z\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import mpu\n",
    "from uszipcode import SearchEngine\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# DATA CLEANING \n",
    "dataset = pd.read_csv('eBay_ML_Challenge_Dataset_2021_train.csv')\n",
    "\n",
    "b2c_c2c = np.array(dataset[\"b2c_c2c\"])\n",
    "seller_id = np.array(dataset[\"seller_id\"])\n",
    "declared_handling_days = np.array(dataset[\"declared_handling_days\"])\n",
    "acceptance_scan_timestamp = np.array(dataset[\"acceptance_scan_timestamp\"])\n",
    "shipment_method_id = np.array(dataset[\"shipment_method_id\"])\n",
    "shipping_fee = np.array(dataset[\"shipping_fee\"])\n",
    "carrier_min_estimate = np.array(dataset[\"carrier_min_estimate\"])\n",
    "carrier_max_estimate = np.array(dataset[\"carrier_max_estimate\"])\n",
    "item_zip = dataset[\"item_zip\"]\n",
    "buyer_zip = dataset[\"buyer_zip\"]\n",
    "category_id = np.array(dataset[\"category_id\"])\n",
    "item_price = np.array(dataset[\"item_price\"])\n",
    "quantity = np.array(dataset[\"quantity\"])\n",
    "payment_datetime = np.array(dataset[\"payment_datetime\"])\n",
    "delivery_date = np.array(dataset[\"delivery_date\"])\n",
    "weight = np.array(dataset[\"weight\"])\n",
    "weight_units = np.array(dataset[\"weight_units\"])\n",
    "package_size = np.array(dataset[\"package_size\"])\n",
    "\n",
    "def b2c_c2c_to_binary(arr):\n",
    "    if arr[0] in [0,1]:\n",
    "        print(\"Array has already been converted to numeric binary!\")\n",
    "    else:\n",
    "        for i in range(arr.shape[0]):\n",
    "            if arr[i][0] == \"B\":\n",
    "                arr[i] = 0\n",
    "            else:\n",
    "                arr[i] = 1\n",
    "            \n",
    "b2c_c2c_to_binary(b2c_c2c)\n",
    "b2c_c2c = np.array(b2c_c2c, dtype=int)\n",
    "\n",
    "def round_datetime_to_date(datetime):\n",
    "    days = datetime.days\n",
    "    hours = datetime.seconds // 3600\n",
    "    if hours > 12:\n",
    "        return days + 1\n",
    "    else:\n",
    "        return days\n",
    "\n",
    "def calculate_handling_and_delivery_days(acceptance_timestamps, payment_timestamps, delivery_date):\n",
    "    handling_labels = []\n",
    "    shipping_labels = []\n",
    "    delivery_labels = []\n",
    "    for i in range(acceptance_timestamps.shape[0]):\n",
    "        raw_payment = payment_timestamps[i]\n",
    "        raw_acceptance = acceptance_timestamps[i]\n",
    "        #parse raw_payment time string to separate year, month, date, and time\n",
    "        p_year, p_month, p_date = int(raw_payment[0:4]), int(raw_payment[5:7]), int(raw_payment[8:10])\n",
    "        p_hour, p_min, p_sec = int(raw_payment[11:13]), int(raw_payment[14:16]), int(raw_payment[17:19])\n",
    "        p_datetime = dt.datetime(year=p_year, month=p_month, day=p_date, hour=p_hour, minute=p_min, second=p_sec)\n",
    "            \n",
    "        #parse raw_acceptance time string to separate year, month, date, and time\n",
    "        raw_acceptance = acceptance_timestamps[i]\n",
    "        a_year, a_month, a_date = int(raw_acceptance[0:4]), int(raw_acceptance[5:7]), int(raw_acceptance[8:10])\n",
    "        a_hour, a_min, a_sec = int(raw_acceptance[11:13]), int(raw_acceptance[14:16]), int(raw_acceptance[17:19])\n",
    "        a_datetime = dt.datetime(year=a_year, month=a_month, day=a_date, hour=a_hour, minute=a_min, second=a_sec)\n",
    "        \n",
    "        raw_delivery = delivery_date[i]\n",
    "        d_year, d_month, d_date = int(raw_delivery[0:4]), int(raw_delivery[5:7]), int(raw_delivery[8:10])\n",
    "        d_date = dt.datetime(year=d_year, month=d_month, day=d_date, hour=17)\n",
    "        \n",
    "        #handling days = acceptance time - payment time; shipping days = delivery date - acceptance time\n",
    "        handling_days = a_datetime - p_datetime\n",
    "        shipping_days = d_date - a_datetime\n",
    "        delivery_days = d_date - p_datetime\n",
    "        \n",
    "        #round to nearest day\n",
    "        rounded_handling_days = round_datetime_to_date(handling_days)\n",
    "        rounded_shipping_days = round_datetime_to_date(shipping_days)\n",
    "        rounded_delivery_days = round_datetime_to_date(delivery_days)\n",
    "        \n",
    "        handling_labels.append(rounded_handling_days)\n",
    "        shipping_labels.append(rounded_shipping_days)\n",
    "        delivery_labels.append(rounded_delivery_days)\n",
    "        \n",
    "    return np.array(handling_labels), np.array(shipping_labels), np.array(delivery_labels)\n",
    "\n",
    "handling_days, shipping_days, delivery_days = calculate_handling_and_delivery_days(acceptance_scan_timestamp, payment_datetime, delivery_date) \n",
    "\n",
    "def convert_weights():\n",
    "    for i, unit in enumerate(weight_units):\n",
    "        if unit == 2:\n",
    "            #convert weight to lbs; 1 kg = 2.20462 lbs.\n",
    "            weight[i] *= 2.20462\n",
    "\n",
    "convert_weights()\n",
    "\n",
    "def determine_weight_averages_by_category_id():\n",
    "    category_id_weights = {}\n",
    "    for i, w in enumerate(weight):\n",
    "        category = category_id[i]\n",
    "        if category not in category_id_weights:\n",
    "            category_id_weights[category] = [w]\n",
    "        else:\n",
    "            category_id_weights[category].append(w)\n",
    "    \n",
    "    category_id_weight_means = {}\n",
    "    for category in category_id_weights:\n",
    "        weights = category_id_weights[category]\n",
    "        average_weight = np.mean(weights)\n",
    "        category_id_weight_means[category] = average_weight\n",
    "    \n",
    "    return category_id_weight_means\n",
    "\n",
    "def fill_missing_weights():\n",
    "    weight_means = determine_weight_averages_by_category_id()\n",
    "    overall_mean = np.mean(weight)\n",
    "    for i, w in enumerate(weight):\n",
    "        if w == 0:\n",
    "            #weight is missing, replace with average weight across same category id\n",
    "            category = category_id[i]\n",
    "            if category in weight_means:\n",
    "                weight[i] = weight_means[category]\n",
    "            else:\n",
    "                #don't have records for this category id, so replace with overall average\n",
    "                weight[i] = overall_mean\n",
    "\n",
    "fill_missing_weights()\n",
    "\n",
    "def string_to_numeric_package_size():\n",
    "    if type(package_size[0]) == int:\n",
    "        print(\"Already converted to discrete numeric values\")\n",
    "    else:\n",
    "        encodings = {\"LETTER\": 0, \"PACKAGE_THICK_ENVELOPE\": 1, \"LARGE_ENVELOPE\": 2,\"VERY_LARGE_PACKAGE\": 3, \n",
    "                     \"LARGE_PACKAGE\": 4, \"EXTRA_LARGE_PACKAGE\": 5, \"NONE\": -1}\n",
    "        for i, size in enumerate(package_size):\n",
    "            package_size[i] = encodings[size]\n",
    "string_to_numeric_package_size()\n",
    "\n",
    "def determine_average_weight_by_package_size():\n",
    "    package_size_weights = {}\n",
    "    for i, w in enumerate(weight):\n",
    "        p_size = package_size[i]\n",
    "        if p_size not in package_size_weights:\n",
    "            package_size_weights[p_size] = [w]\n",
    "        else:\n",
    "            package_size_weights[p_size].append(w)\n",
    "    \n",
    "    package_id_weight_means = {}\n",
    "    for p_size in package_size_weights:\n",
    "        weights = package_size_weights[p_size]\n",
    "        average_weight = np.mean(weights)\n",
    "        package_id_weight_means[p_size] = average_weight\n",
    "    \n",
    "    return package_id_weight_means\n",
    "\n",
    "def fill_missing_package_sizes():\n",
    "    weight_means = determine_average_weight_by_package_size()\n",
    "    weight_means.pop(-1, None)\n",
    "    weight_means_list = [weight_means[key] for key in weight_means]\n",
    "    for i, s in enumerate(package_size):\n",
    "        if s == -1:\n",
    "            #package size is missing, replace with package size it's weight is closest to the average of\n",
    "            w = weight[i]\n",
    "            abs_function = lambda value: abs(value-w)\n",
    "            closest_value = min(weight_means_list, key=abs_function)\n",
    "            closest_p_size = weight_means_list.index(closest_value)\n",
    "            package_size[i] = closest_p_size\n",
    "\n",
    "fill_missing_package_sizes()\n",
    "\n",
    "def determine_average_shipping_estimates_by_shipment_method():    \n",
    "    carrier_min_by_shipment_method = {}\n",
    "    carrier_max_by_shipment_method = {}\n",
    "    for i, method_id in enumerate(shipment_method_id):\n",
    "        carrier_min = carrier_min_estimate[i]\n",
    "        carrier_max = carrier_max_estimate[i]\n",
    "        if method_id not in carrier_min_by_shipment_method:\n",
    "            carrier_min_by_shipment_method[method_id] = [carrier_min]\n",
    "        else:\n",
    "            carrier_min_by_shipment_method[method_id].append(carrier_min)\n",
    "\n",
    "        if method_id not in carrier_max_by_shipment_method:\n",
    "            carrier_max_by_shipment_method[method_id] = [carrier_max]\n",
    "        else:\n",
    "            carrier_max_by_shipment_method[method_id].append(carrier_max)\n",
    "    \n",
    "    carrier_min_means = {}\n",
    "    for method_id in carrier_min_by_shipment_method:\n",
    "        min_estimates = carrier_min_by_shipment_method[method_id]\n",
    "        mean_min_estimate = np.mean(min_estimates)\n",
    "        carrier_min_means[method_id] = mean_min_estimate\n",
    "    \n",
    "    carrier_max_means = {}\n",
    "    for method_id in carrier_max_by_shipment_method:\n",
    "        max_estimates = carrier_max_by_shipment_method[method_id]\n",
    "        mean_max_estimate = np.mean(max_estimates)\n",
    "        carrier_max_means[method_id] = mean_max_estimate \n",
    "    \n",
    "    return carrier_min_means, carrier_max_means\n",
    "\n",
    "def fill_missing_carrier_estimates():\n",
    "    #consider replacing missing values with estimates with similar distance\n",
    "    carrier_min_means, carrier_max_means = determine_average_shipping_estimates_by_shipment_method()\n",
    "    overall_min_mean, overall_max_mean = np.mean(carrier_min_estimate), np.mean(carrier_max_estimate)\n",
    "    for i, estimate in enumerate(carrier_min_estimate):\n",
    "        if estimate < 0:\n",
    "            #need to fill value \n",
    "            method_id = shipment_method_id[i]\n",
    "            if method_id in carrier_min_means:\n",
    "                carrier_min_estimate[i] = carrier_min_means[method_id]\n",
    "            else:\n",
    "                carrier_min_estimate[i] = overall_min_mean\n",
    "    for i, estimate in enumerate(carrier_max_estimate):\n",
    "        if estimate < 0:\n",
    "            #need to fill value\n",
    "            method_id = shipment_method_id[i]\n",
    "            if method_id in carrier_max_means:\n",
    "                carrier_max_estimate[i] = carrier_max_means[method_id]\n",
    "            else:\n",
    "                carrier_max_estimate[i] = overall_max_mean\n",
    "\n",
    "fill_missing_carrier_estimates()\n",
    "\n",
    "def fill_missing_declared_handling_days():\n",
    "    overall_mean = np.mean(declared_handling_days)\n",
    "    seller_counts = Counter(seller_id)\n",
    "    for i, days in enumerate(declared_handling_days):\n",
    "        if np.isnan(days):\n",
    "            #need to fill\n",
    "            declared_handling_days[i] = overall_mean\n",
    "\n",
    "features = np.column_stack((b2c_c2c, seller_id, declared_handling_days, shipment_method_id, shipping_fee,\n",
    "                             carrier_min_estimate, carrier_max_estimate, category_id,\n",
    "                             item_price, weight, quantity, package_size, handling_days))\n",
    "labels = np.array(delivery_days)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(features.shape)\n",
    "features = scale(features, with_mean = True, with_std=True)\n",
    "print(features.shape)\n",
    "indeces = ~np.isnan(features).any(axis=1)\n",
    "print(indeces)\n",
    "features = features[~np.isnan(features).any(axis=1)]\n",
    "print(features.shape)\n",
    "labels = labels[indeces]\n",
    "handling_days = handling_days[indeces]\n",
    "shipping_days = shipping_days[indeces]\n",
    "print(labels.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(15000000, 13)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/CAMPUS/hfma2018/.local/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:235: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(15000000, 13)\n",
      "[ True  True  True ...  True  True  True]\n",
      "(14297114, 13)\n",
      "(14297114,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "features = features[:, :-1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "model = LinearRegression()\n",
    "model.fit(features, labels)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(model.coef_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-8.09795735e-02  6.55274933e-02  8.86068784e-01  2.11399948e-02\n",
      " -6.52588741e-02  1.51823145e-01  4.41767331e-01  1.02764189e-01\n",
      " -2.32173062e-02 -4.01198415e-04  9.72705709e-03  6.45949975e-02]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "What if we use lasso regression? An $l_1$ norm will push irrelevant features weights to 0. This will tell us which features are unimportant to the shipping prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "lasso_model = linear_model.Lasso(alpha=1.0)\n",
    "lasso_model.fit(features, labels)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Lasso()"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(lasso_model.coef_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0.  0.  0.  0.  0. -0.  0.  0. -0.  0. -0.  0.]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, let's use the visualization package __ to visualize the trees learned by XGBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we've learned more about feature importance for the entire delivery prediction (handling time + shipping time), it may be useful to look into whether some features are only important for the handling portion and don't affect the shipment portion, and vice versa. So we will apply the tactics above both (1) when the labels are only the handling time, and (2) when the labels are only the shipment time."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "handling_linreg = LinearRegression()\n",
    "handling_linreg.fit(features, handling_days)\n",
    "print(handling_linreg.coef_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.07389143  0.05425154  0.86970894 -0.01883299 -0.03151593  0.00414523\n",
      "  0.02560026  0.02273071  0.00155812  0.0014169   0.0193101  -0.01256442]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "shipping_linreg = LinearRegression()\n",
    "shipping_linreg.fit(features, shipping_days)\n",
    "print(shipping_linreg.coef_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.01864717  0.01194991  0.01481685  0.03913644 -0.03807706  0.14917728\n",
      "  0.4133649   0.07600417 -0.02316963 -0.00150535 -0.00724451  0.07959303]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "lasso_handling = linear_model.Lasso(alpha=0.05)\n",
    "lasso_handling.fit(features, handling_days)\n",
    "print(lasso_handling.coef_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.          0.          0.81013996 -0.         -0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.        ]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "lasso_shipping = linear_model.Lasso(alpha=0.15)\n",
    "lasso_shipping.fit(features, shipping_days)\n",
    "print(lasso_shipping.coef_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.         -0.          0.          0.         -0.          0.\n",
      "  0.22663033  0.         -0.         -0.         -0.          0.        ]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from collections import Counter\n",
    "c = Counter(buyer_zip)\n",
    "print(c[\"00000\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "11\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's analyze the details of `payment_datetime` and `acceptance_scan_timestamp`. More specifically, let's breakdown the month, day of month, weekday, and whether or not the date is a holiday. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "import datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "#acceptance_scan_timestamp\n",
    "#payment_datetime\n",
    "trial_acceptance = acceptance_scan_timestamp[:10]\n",
    "trial_payment = payment_datetime[:10]\n",
    "\n",
    "# only grab the date, we don't care about the timestamp\n",
    "def grab_date(x):\n",
    "    return x[:10]\n",
    "\n",
    "# vectorize the function\n",
    "grab_date_vectorized = np.vectorize(grab_date)\n",
    "\n",
    "a_date = grab_date_vectorized(acceptance_scan_timestamp)\n",
    "p_date = grab_date_vectorized(payment_datetime)\n",
    "\n",
    "# turn the date string into a datetime \n",
    "def convert_to_datetime(x):\n",
    "    dt_format = \"%Y-%m-%d\"\n",
    "    return  datetime.datetime.strptime(x, dt_format)\n",
    "\n",
    "convert_to_datetime_vectorized = np.vectorize(convert_to_datetime)\n",
    "\n",
    "a_datetime = convert_to_datetime_vectorized(a_date)\n",
    "p_datetime = convert_to_datetime_vectorized(p_date)\n",
    "\n",
    "# get month\n",
    "def grab_month(x):\n",
    "    return x.month\n",
    "\n",
    "grab_month_vectorized = np.vectorize(grab_month)\n",
    "\n",
    "a_month = grab_month_vectorized(a_datetime)\n",
    "p_month = grab_month_vectorized(p_datetime)\n",
    "\n",
    "# get day/month\n",
    "# def grab_day_month(x):\n",
    "#     return x[5:10]\n",
    "\n",
    "# grab_day_month_vectorized = np.vectorize(grab_day_month)\n",
    "\n",
    "# trial_acceptance_day_month = grab_day_month_vectorized(trial_acceptance)\n",
    "# trial_payment_day_month = grab_day_month_vectorized(trial_payment)\n",
    "\n",
    "# get day of week --> number 0-6 corresponding to Mon-Sun\n",
    "def get_weekday(x):\n",
    "    return x.weekday()\n",
    "\n",
    "get_weekday_vectorized = np.vectorize(get_weekday)\n",
    "\n",
    "a_weekday = get_weekday_vectorized(a_datetime)\n",
    "p_weekday = get_weekday_vectorized(p_datetime)\n",
    "\n",
    "\n",
    "# is holiday?\n",
    "import holidays\n",
    "us_holidays = holidays.UnitedStates()\n",
    "\n",
    "def is_holiday(x):\n",
    "    return x in us_holidays\n",
    "\n",
    "is_holiday_vectorized = np.vectorize(is_holiday)\n",
    "\n",
    "a_is_holiday = is_holiday_vectorized(a_date)\n",
    "p_is_holiday = is_holiday_vectorized(p_date)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "features = np.column_stack((a_month, p_month,\n",
    "                            a_weekday, p_weekday,\n",
    "                            a_is_holiday, p_is_holiday))\n",
    "features"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 3,  3,  1,  6,  0,  0],\n",
       "       [ 6,  6,  5,  4,  0,  0],\n",
       "       [ 1,  1,  0,  6,  0,  0],\n",
       "       [12, 12,  0,  6,  0,  0],\n",
       "       [ 7,  7,  4,  3,  0,  0],\n",
       "       [ 4,  4,  4,  3,  0,  0],\n",
       "       [ 2,  2,  4,  4,  0,  0],\n",
       "       [ 4,  4,  0,  6,  0,  0],\n",
       "       [10, 10,  5,  4,  0,  0],\n",
       "       [ 8,  8,  4,  3,  0,  0]])"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert the zipcodes to floats and see what happpens in the models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}